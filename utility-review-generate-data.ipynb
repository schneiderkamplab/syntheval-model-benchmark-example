{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for documenting how the synthetic data can be generated\n",
    "\n",
    "In this notebook we show our process for generating the synthetic data used for the model benchmark. The data is generated using the SynthCity library for CTGAN, Datasynthesizers, and the synthpop CART model accessed in R. \n",
    "\n",
    "This part is here for reproducibility purposes, but is not required to run the benchmark part if using the existing datasets in the repository. Since generating everything can be a long and slow process, we recommend running the same code in the `generate_datasets.py` script on a more powerful machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import notebook\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from syntheval import SynthEval\n",
    "from utils.utils import prepare_directories\n",
    "from utils.gen_interfacer import generate_synthetic_data\n",
    "\n",
    "np.random.seed(0)   # remove seed lock for true randomness\n",
    "\n",
    "### Parameters\n",
    "\n",
    "NUM_REPEATS = 3\n",
    "\n",
    "target_vars = {\n",
    "    'data/small_few_atts/diabetes': 'Outcome',\n",
    "    'data/small_few_atts/penguins': 'species',\n",
    "    'data/small_few_atts/titanic': 'Survived',\n",
    "    'data\\small_some_atts\\cervical_cancer': 'Biopsy',\n",
    "    'data\\small_some_atts\\derm': 'class',\n",
    "    'data\\small_some_atts\\spect': 'OVERALL_DIAGNOSIS',\n",
    "    'data\\small_many_atts\\diabetic_mellitus': 'TYPE',\n",
    "    'data\\small_many_atts\\mice_protein': 'class',\n",
    "    'data\\small_many_atts\\spectrometer': 'ID-type',\n",
    "    'data\\large_few_atts\\space_titanic': 'Survived',\n",
    "    'data\\large_few_atts\\stroke': 'stroke',\n",
    "    'data\\large_few_atts\\winequality': 'quality',\n",
    "    'data\\large_some_atts\\cardiotocography': 'Class',\n",
    "    'data\\large_some_atts\\one_hundred_plants': 'Class',\n",
    "    'data\\large_some_atts\\steel_faults': 'class',\n",
    "    'data/large_many_atts/bankruptcy': 'Bankrupt',\n",
    "    'data/large_many_atts/speed_dating': 'match',\n",
    "    'data/large_many_atts/yeast_ml8': 'class1',\n",
    "}\n",
    "\n",
    "generative_model_names = ['ctgan', 'datasynthesizer', 'synthpop']\n",
    "\n",
    "GENERATE_MISSING = True\n",
    "GENERATE_OVERWRITE = False\n",
    "\n",
    "### Code to generate synthetic datasets\n",
    "def work_func(iterable, num_reps = 3):\n",
    "    dataset_name, generative_model =  iterable\n",
    "    try: \n",
    "        if GENERATE_OVERWRITE: raise Exception(\"Regenerate the synthetic datasets\")\n",
    "        df_syn = pd.read_csv(dataset_name + '_' + generative_model + '.csv')\n",
    "    except:\n",
    "        if not GENERATE_MISSING: return None\n",
    "        dfs = {i: generate_synthetic_data(dataset_name, generative_model) for i in range(num_reps)}\n",
    "        \n",
    "        df_train = pd.read_csv(dataset_name +'_train.csv')\n",
    "        df_test = pd.read_csv(dataset_name + '_test.csv')\n",
    "\n",
    "        SE = SynthEval(df_train, df_test, verbose=False)\n",
    "        df_comb , _ = SE.benchmark(dfs, target_vars[dataset_name],'./fast_eval.json')\n",
    "\n",
    "        idx = df_comb['rank'].idxmax() # get the best dataset\n",
    "\n",
    "        dfs[idx].to_csv(dataset_name + '_' + generative_model + '.csv', index=False)\n",
    "\n",
    "        for f in glob.glob(\"SE_benchmark_*.csv\"):\n",
    "            os.remove(f)\n",
    "\n",
    "    return None\n",
    "\n",
    "prepare_directories(target_vars)\n",
    "\n",
    "iterables_list = list(product(target_vars, generative_model_names))\n",
    "_ = Parallel(n_jobs=-2)(delayed(work_func)(iterable, NUM_REPEATS) for iterable in notebook.tqdm(iterables_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
